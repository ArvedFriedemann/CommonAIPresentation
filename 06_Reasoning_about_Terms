Reasoning about Terms

This part is about explaining how to reason about an active search state within the state itself. In other words, when we are given knowledge in form of a conjunction with either facts or disjunctions, how could we derive from the facts how to narrow down the disjunctions, when Andorra would otherwise fail? The clue is that we can contain meta statements that can give additional facts about the disjunctions that may only be based on the structure of the disjunction, not its actual contents.

We allow for the following Term structure.

or Term X, address X
[] Term (X Y), Term X, Term Y
end

So a term is either just an address (or name, or variable) or the product of two terms. To create a language from terms, we define some fixed names for constants.

=   for equality of two terms,
\=  for inequality,
,   for conjugation, (alternatively, a linebreak)
or    as opener for disjunction,
[]    for disjunction constructor,
end   for closing an opener,
bind X in E end     as existential variable binding
forall X in E end   as universal variable binding
not   for intuitionistic negation
new   to create a variable containing a new constant (modelled as variable pointing to itself).

Their interpretation is intended to be the general first order semantics, inspired by Oz.
What is new here is the "forall" binding. Its use is motivated for meta reasoning.

A search state is a conjunction of terms, itself being a term as well. This term could contain information about how terms could be evaluated. Let's look at an example.

or A [] B [] C end
not A
not B

Where A, B and C a terms, or rather some statements. As we know that A and B do not hold, the Andorra principle infers that C holds. In this example, knowledge about the provability of A and B are contained in the top level conjunction. This is knowledge that otherwise could only be inferred by trying both A and B, so having not A and not B on top level gives a shortcut.

Here, we have another example:

or A, B
[] B, A
end

This example is somewhat constructed, but it is easy to see that this should become the statement A, B. This would happen by adding the following fact:

forall X Y in ( (or X, Y [] Y, X end) , X, Y) end

The semantics of the forall in this case is that it evaluates to a conjunction of all terms that come from substituting A and B with existing variables. There is a problem with these semantics, but we will get to that later.
If X and Y are instantiated to A and B respectively, the easier to handle facts A and B emerge. There is a way to do this without the special "forall" symbol, but this way looks more intuitive. Long story short: If general information about the search is derived, it can make the search faster and help the Andorra principle to make more disjunctions deterministic.

The problem with the above formulation is that the universal rule is not defined as an implication. "If a term has the shape (or X, Y [] Y, X end) then also X and Y hold" should be more of what is expressed. This can be done by defining something like a "function on terms" that is then mapped over a conjunction, for example. In a Haskell\AGDA-mix this would look like

transform :: Term -> Term
transform (or X, Y [] Y, X end) = X, Y
transform t = t

applyUniversal :: [Term] -> (Term -> Term) -> [Term]
applyUniversal conjuncts deduction = conjuncts ++ (concatMap deduction conjuncts)

Of course, this can also be expressed in the logical language, but I want to omit the technical details. In the logical language we now want to express something like a map on a list, where the function to map is contained in the list itself. Again, in our fictional functional mix language, this could look like

selfTransform :: [Either Term (Term -> Term)] -> [Either Term (Term -> Term)]
selfTransform lst = lst ++ ((rights lst) <*> (lefts lst))

(please note that in the list monad, the <*> applies all functions from the left list to all arguments in the right list. For reference: https://en.wikibooks.org/wiki/Haskell/Understanding_monads/List)

This would apply all (encoded) functions to the terms in their contexts (possibly their own encoding). It should be noted, but for now not further followed, that when doing something like an "attempt", where we try out an assignment without moving the new facts to the topmost context, these functions should also traverse to this lower context. If this is confusing don't think about it now, it is an easy to solve but very technical problem.

What causes headache here is that obviously each function in the list has a term representation, while also each term represents a function. So there are functions eval :: Term -> (Term -> Term) and encode :: (Term -> Term) -> Term, where the encode function cannot usually be expressed in functional languages. The takeaway message is: By modifying the terms, we also modify the functions that should be mapped over the terms etc. This way, we can transport knowledge from terms onto the terms themselves. If done wrong, this can get heavily computationally expensive. Imagine deducing an identity function and always applying it to each variable. This problem can be solved, but will be addressed later.


What works in the functional context also works in the logical one. Either it is already implemented that the "forall" rules are mapped over all statements in the conjunction, then nothing more needs to be done. If no such forall statement exists, one always needs the variable in which the current general term is stored. Let's call it SELF. In this case, the conjunction contains something like "map RULE on SELF", where RULE is the statement from earlier. This is one of the mechanics needed to create a solver with a solver. Facts about search are deduced and then directly mapped to the current knowledge.

---------------------------------------------------------------------------
--
---------------------------------------------------------------------------

We now get into more detail on what exactly will be deduced in terms of meta knowledge. In a nutshell, the search can cache search results to form shortcuts through the computation. This is a generalised form of clause learning. Due to the functional consistency, any functional language could technically do it. As same inputs always give the same outputs in a function, if a functuion applies itself recursively for a long time, it could cache the computed result and the next time the same inputs come, it retrieves the outcome from the cache. The challenge here is to determine what to cache. If every possible function call is cached, already querying the cache would be way too computationally expensive. Therefore, only those clauses that can provably speed up the search are being remembered.

Before we go to the general solution on how to do this, let's look more concretely at how we would implement the caching for functions. We assume a function f to be initially implemented by a set of disjunct clauses C = C1 ... Cn. We cant a clause set C' = C1' ... Cm' that implements the same function f, but is higher with respect to some complexity criterion. Fixing this criterion is a bit hard because technically, there could be tradeoffs. For simplicity, let's focus on a strict complexity criterion, where it holds that for each input x, the complexity of (f x) over C' is lower or equal than over C. This means that clauses are only added if adding them does not slow any other input, and if adding them gives some kind of speedup.
When performing a computation on f, there are a lot of possible clauses emerging for C', namely all computation traces that start with a call to f. For all of those, the runtime is measured. If a clause is added to C', the runtime of the function at the given inputs is reduced to the number of steps that is needed to identify that the input belongs to this clause. If this gives a performance boost, the clause is kept.
What's further challenging is that clauses can dominate each other. The clauses determine which sets of inputs point to which outputs. If a more general clause is found, all specific clauses can be removed, again, if there is computational benefit.
If the clauses for optimization are taken from the running traces of the function itself, it can be considered a passive optimization and it can even happen in parallel to the actual computation. The computation can be occasionally stopped to exchange the optimised function for the old one, giving a spiral of optimisation. Contrary to that, there would be active optimisation, which would be creating a proof that there can be no more clauses added that would improve the speed of the function. In this case, the function would be actively tested on constructed inputs to check the validity of that statement.




Let's investigate this for logical terms. The cool thing about logical languages is that we assume that everything that can be parallelised will be, so the extraction of trace information will be executed in parallel to the program running and producing the traces. What is hard in logical languages i to e.g. exchange an older version of a function implementation with a new one, as every value is immutable. Language like Oz do provide mutable values, but let's focus on the easier case.

The program traces are nothing but the facts that are produced when running some function, like f. The knowledge base will contain all intermediate traces, like f x1, fx2, ... , as well as the time the implementation C took to evaluate it. Some other logical term now states "If f x on C took n steps and the cache pays off, then the cached clause is in C'".

Technically, logical languages already provide such a cache. In an ideal implementation, no fact is evaluated twice, meaning that the computation on a fix memory is only ever done once. What is not contained in this is a cache that can be used for future computation, meaning one that acts on content equality, not pointer equality.
--TODO: couldn't this just be achieved by storing constraints in a normalised form? Also...why logical languages don't already store their meta information on their blackboards?
--Normalised form only works for constants, not for universal values! Constraints need to be compressed as well.

Just a thought but: Seemingly the only state based thing necessary would be the garbage collector. Which knowledge to keep and which not. This would be controlled by upcoming facts as well. The base knowledge needs to be kept, additional knowledge can be kept if it gives an advantage.

Notes for concretisation:
Term structure needs to be fix.
What is the concrete interface between conjunction of facts and andorra?
How does term compression work?
what is the concrete syntax for proofs?

Things are only done when a proof exists that they are legal, or likewise, they are definitely done when there is proof that they are necessary. To prove things there needs to be existential and universal statements. Existential is just the binder. Universal would be the negation of the recursion. So, not only travel statements from the state into the evaluation, but the evaluation also creates statements in the state. It carries a pointer to the old state, and when andorra is done, it puts this information in the state, together with the outcome, the nondeduced variables etc. Afterwards, the andorra has to run again, now on the enhanced state, producing, again, new facts and so on.

What is needed now: Andorra now technically caches everything. All function calls, all outcomes etc. So how does the memory management work?
Problem: Formulating it by hand is too complex. It needs to be done by some proof that is done during execution.
Likely outcome: Some statements ensuring completeness of search. Some constraints on resources like time and memory that only have to propagate when known. Results in waste of resources in the beginning, but that converges to small overhead later.

TODO: How would branching or backtracking be formulated here? Just with pointers to some old state? Is that sufficient? Could that result in too much information to be lost? During search, general information should already be created that is not affected by backtrack

TODO: Outlook: The whole system should make a proof of its own correctness, workings etc. Then it would produce its own benchmarks.
