The Possibility of Self Improving Solving Systems

Self improving machines. A technology every computer scientists knows we need, though despite significant progress on special cases, we have never managed to actually create a fully universal self improving program. The frustration made us push the idea into the realm of science fiction. Yet, During the course of my PhD, I found that not only are these machines theoretically possible, but very much in graspable range to actually be implemented with already or soon existing tools. Here is a concrete description of how we can build one.

The fundamental tool needed are so-called logical languages, with an evaluation method known as the "Andorra Principle". Let me give a quick recap. For those of you who already worked with logical languages or the andorra principle, feel free to look in the video description for time stamps.

In logical languages, we assume the memory to be a set of statements declaring that a certain variable (comparable to a pointer or address) has a certain content. These contents can be anything from a simple boolean to, e.g. a readable sentence. When we start computation, some of these assignments are not known. Sure, we e.g. rarely know the output of our program before we actually run it. Computation itself is not a sequence of deductions. If we know the value of some values, like our inputs, we can deduce the values of the outputs. Because we don't want to tell our computers how to do their job, we can just formulate constraints on memory as conjunction of assignments. For an addition e.g. this would look like "add X Y Z and X=0 and Y=Z". If X, Y and Z are some variables in the memory that we want to add, and the X is 0, then we know  that Y needs to equal Z. In more familiar language, we would state that "0+X=X", but we will et in a second to why it can help to think in a different syntax for now.
Logical languages can be seen as a database of knowledge on the memory. We could query the information "add X Y Z", so "is Z the result of adding X and Y" and get some answer, or we can force information, like "make Z be the result of X and Y", which would result in the variables to be assigned as we specified in the conjunction.
Of course, this would be rather boring if we had no case distinctions, or better, conjunctions. In a conjunction, we can have several so called clauses, like out conjunctions from atop, but only one of them suffices to hold. So, as a simple list example:
or isEmpty X Y and X=empty and Y=true
[] isEmpty X Y and X=(list Head Tail) and Y=false
end
with syntax inspired by the language "Oz", or, with a more compact functional or PROLOG style syntax,
isEmpty empty true.
isEmpty (list Head Tail) false.
The reason we write these statements this way is that we don't want to care for the exact order in which these constraints are evaluated. Evaluation of a conjunction works such that just all constraints like e.g. assignments are put into the memory. For conjunction, we need the andorra principle.

As in a conjunction we cannot always tell which branch to take, the conjunction constraint waits for the contained values to be evaluated. Essentially, it is checked whether for the current memory assignment only one possible branch remains. If that is the case, this branch will be executed and its statements will be used to further assign the memory. If more than one possible branch remains, the computation is frozen, until maybe another assignment from somewhere sufficiently instantiates the variables to make the next steps clear.
Long story short: We write our instructions just like in any normal programming language, but give them the ability to choose. The choice is only executed when it is clear from the memory which choice was taken.

It should be noted how this principle works multi directional. It could be that we already know the output to a function, but do not know its input. If we e.g. force isEmpty Y true, then we know that Y=empty, because that's what's written in the clause. Same, if we force isEmpty Y false, we at least know the list must have one value in it, so it at least looks like Y=(list Head Tail). This multi directionality is absolutely crucial, because, as we will see later, we can express circular statements with it, which makes the whole self-improvement possible.


Now, again, for some bigger picture. These languages allow for incomplete code to at least run "as long as possible". This is already quite important for software development. Imagine you could scribble some incomplete code, and then run it to interactively add details. While you still imagine that, we can already find that of course, when getting access to this incomplete state, we could write a program that completes it, which is exactly what a solver does.

What is furthermore quite directly possible with logical languages is meta reasoning. So far, our language terms have only been made up of variables, some constants, equality, variable binding, conjunction and disjunction, with most important constants being values like booleans and tuple constructors. This way, we could write a constraint (Term T), which would constrain T to be a language term that could be natively evaluated with (Eval T). This means that we could deduce language terms and immediately evaluated them, such that we don't even need to state our full program when programming. We just have to make sure that it will be deduced at some point.

This already gives the initial setup for self improving solvers. A solver is a term M, such that for every input term T, Eval (apply M T) deduces all variables using only andorra evaluation. The constraints ensuring this could be (PropagateAll (apply M T)). Constraining this already gives bookkeeping about what information is missing on how to assign unassigned values for example. This alone is already a strong tool, but the magic happens when we put the following: (PropagateAll (apply M (apply M T))). Now, we are not only employing the solver to solve some task, but also to solve its own incomplete implementation! Let us let it sink in for a second what that means. Assume we find any information about how a tiny piece of the solver should look like. This means that some variables in M are being assigned. This could resolve in disjunctions becoming deterministic, meaning that the solver is being evaluated a bit more. This evaluation could mean that it finds more assignments for its own implementation, evaluating it even further and so on. This maximises the speed at wich the solver is being created and it prevents the programmer from having to solve the same issue over and over.

Of course, just stating that everything should be propagated is not enough to actually create the solver. The reason is that it is still ambiguous as to which assignment the solver should propagate to, in the case that there are several possibilities. There are cases where it is quite reasonable for a solver to not further propagate in case there are several solutions, but for now we assume that if there is a choice, the solver should propagate to the fastest possible findable assignment.
Complexity information can be gathered from a constraint "(Propagate T T' I)", which takes a partially assigned term and assigns the term after andorra evaluation, possibly giving extra information in I, like the amount of steps taken or the memory used. The next thing might seem like a bit of a sledgehammer approach, but the issue will be resolved later. Every disjunction branch in the term representation of a term T will additionally be associated with an I with (Propagate T T' I), so that there is access to the meta information about what would happen if that branch were to be executed. Here, the lazyness principle should help not to evaluate this information for disjunctions that turn deterministic with the andorra principle, or, vice versa, if the branch is executed, the information is deduced as a side product anyway. In case of a choice even after andorra propagation terminated, the next deduced branch is the one that leads to a complete assignment the fastest.

On first sight, this looks like a massive waste of time and memory. It is already crazy enough that we are querying information that would usually only be accessible in the future after evaluation. Luckily, logical languages allow this. In fact, by retrieving information on our computation that would need the computation to evaluate, the computation will already be evaluated, at least at some position in the memory. This prevents the computation from being done twice (if you keep in mind that information from the tried out branch needs to be transferred into the originally queried memory). There is one remaining memory and time leak from this that results from the andorra evaluation, that we will fix in a second.

Before that though, one final concept on how to close one remaining gap. Let's assume the complexity information is encoded without explicit splitting, but it is information that is just a side effect from computation. This would not waste as much memory, but especially in the beginning barely anything could propagate because of the vast amount of missing information. Still, all constraints necessary have been put into place, so some choice needs to be made. This choice could be either by an oracle like a human, or by randomness. In fact, if no oracle is available, randomness is the only possible alternative as all knowledge that we could have deduced was being deduced and it did not suffice. Around this part, backtracking mechanisms that can be evaluated using the andorra propagation need to be set in place, but the bigger picture is:
The aim is to create so many constraints that, if after andorra evaluation information is still missing, the only reasonable way to go forward is randomness.

This leads to the next idea of how to use this to build solvers that also work under resource constraints. In fact, the andorra principle is nice, but in itself it could result in too many constraints to be evaluated at the same time. Sometimes, it might be reasonable not to propagate something if e.g. at another point there is an error known to occur..
%TODO: could it be that andorra already kinda does that? You know..a branch is only evaluated when it is known that it has benefits...
